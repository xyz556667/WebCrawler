{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import csv\n",
    "import os\n",
    "import datetime\n",
    "from opencc import OpenCC\n",
    "import re\n",
    "import chardet\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from tqdm import trange\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 連線與建資料庫，有建立過不用再建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #連線\n",
    "# Database = pymysql.connect(host=\"localhost\", user=\"root\", password=\"mysql\")\n",
    "# cursor = Database.cursor()\n",
    "# cursor.execute(\"drop database if exists cnyes_news\") #刪資料庫\n",
    "# cursor.execute(\"create database cnyes_news character set utf8 collate utf8_general_ci\") #建資料庫\n",
    "#登入\n",
    "Database = pymysql.connect(host=\"localhost\", user=\"root\", password=\"mysql\", db=\"cnyes_news\")\n",
    "Cursor=Database.cursor()\n",
    "Cursor.execute(\"use cnyes_news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立table，有建立過不用再建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimmy\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (3719, \"'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.\")\n",
      "  result = self._query(query)\n",
      "C:\\Users\\jimmy\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:170: Warning: (3778, \"'utf8_general_ci' is a collation of the deprecated character set UTF8MB3. Please consider using UTF8MB4 with an appropriate collation instead.\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "# # for TableName in ['tw_stock','wd_stock','cn_stock','forex','future','cnyeshouse']:\n",
    "# for TableName in ['tw_stock']:\n",
    "#     #刪除表\n",
    "# #     Cursor.execute(\"drop table if exists %s\"%(TableName))\n",
    "#     #建立表\n",
    "#     Cursor.execute(\"drop table if exists %s\"%(TableName))\n",
    "#     BuiltQuery = \"\"\"CREATE TABLE %s (ID bigint(10) NOT NULL AUTO_INCREMENT PRIMARY KEY,\n",
    "#                              Created TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "#                              Datatime bigint(12),\n",
    "#                              Newstime bigint(12),\n",
    "#                              Source varchar(1000) CHARACTER SET utf8 COLLATE utf8_general_ci,\n",
    "#                              Header varchar(1000) CHARACTER SET utf8 COLLATE utf8_general_ci,\n",
    "#                              Content text CHARACTER SET utf8 COLLATE utf8_general_ci,\n",
    "#                              Target varchar(1000) CHARACTER SET utf8 COLLATE utf8_general_ci,\n",
    "#                              URL varchar(1000) CHARACTER SET utf8 COLLATE utf8_general_ci)\"\"\" %(TableName)\n",
    "#     Cursor.execute(BuiltQuery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### api格式 https://news.cnyes.com/api/v3/news/category/{專欄分類}?startAt={開始日期}&endAt={結束日期}&limit=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tw_stock\n"
     ]
    }
   ],
   "source": [
    "# for category in ['tw_stock','wd_stock','cn_stock','forex','future','cnyeshouse']:  \n",
    "for category in ['tw_stock']:  \n",
    "    print(category)\n",
    "    FindQuery = \"\"\"select max(Newstime) from %s\"\"\" %(category) #找出目前資料庫最新日期(a)\n",
    "    Cursor.execute(FindQuery)\n",
    "    MaxNewstime=str(Cursor.fetchall()[0][0])[0:8] #把cursor資料全抓出，[0][0]剛好取出數字(int)，然後轉成str，取日期共8位數\n",
    "    MaxNewstime = time.mktime(time.strptime(MaxNewstime, \"%Y%m%d\"))#轉成時間戳\n",
    "    Nowtime = time.mktime(time.strptime(datetime.datetime.now().strftime(\"%Y-%m-%d\"),\"%Y-%m-%d\")) #執行程式日期(b)，一樣轉成時間戳\n",
    "    Days = (Nowtime-MaxNewstime)/(60*60*24) #時間戳互減，並轉換成天數格式\n",
    "    \n",
    "    for i3 in range(int(Days-1)): #爬取(a+1)至(b-1) \n",
    "        #重點抓出max page\n",
    "        bench_time = int(MaxNewstime + 60*60*24*1) #現有資料庫最新日期(a)隔天(a+1)\n",
    "        start_time = bench_time + 60*60*24*i3 #從a+1到b-1\n",
    "        link1=\"https://news.cnyes.com/api/v3/news/category/%s?startAt=%s&endAt=%s&limit=30\"%(category,str(start_time),str(start_time)) #注意catergory、startAt、endAt\n",
    "        reqs = requests.get(link1)\n",
    "        reqsjson = json.loads(reqs.text)\n",
    "        max_page = reqsjson['items']['last_page']\n",
    "        \n",
    "        for i2 in range(max_page): \n",
    "            #重點抓出每頁js內容\n",
    "            link2=\"https://news.cnyes.com/api/v3/news/category/%s?startAt=%s&endAt=%s&limit=30&page=%s\"%(category,str(start_time),str(start_time),i2+1)\n",
    "            reqs = requests.get(link2)\n",
    "            reqsjson = json.loads(reqs.text)\n",
    "\n",
    "            for i1 in range(len(reqsjson['items']['data'])): #第N篇新聞，前面有設定limit30\n",
    "                TableName=category #資料庫table\n",
    "                datatime=datetime.datetime.now().strftime('%Y%m%d%H%M%S')[0:12] #爬蟲抓新聞的時間\n",
    "                Newstime=time.strftime('%Y%m%d%H%M%S',time.localtime(reqsjson['items']['data'][i1]['publishAt']))[0:12] #抓出新聞發布時間\n",
    "                Source=reqsjson['items']['data'][i1]['categoryId']\n",
    "                Header=reqsjson['items']['data'][i1]['title'].replace(\"\\n\",\" \").replace(\"\\\\\",\"\\\\\\\\\").replace('\"',r'\\\"')\n",
    "                \n",
    "                #抓出標的公司\n",
    "                Target=''\n",
    "                for i0 in range(len(reqsjson['items']['data'][i1]['market'])): #抓出標的公司名稱與代碼\n",
    "                    tmpp=reqsjson['items']['data'][i1]['market'][i0]['name']+reqsjson['items']['data'][i1]['market'][i0]['code']\n",
    "                    Target=Target+tmpp+','  #可能不只一個，中間用逗號隔開\n",
    "                if Target != \"\":\n",
    "                    Target=Target[:-1] #不留下最後一個逗號\n",
    "                    \n",
    "                url=\"https://news.cnyes.com/news/id/\"+str(reqsjson['items']['data'][i1]['newsId'])#新聞網址\n",
    "                response = requests.get(url)\n",
    "                soup = BeautifulSoup(response.text,'lxml')\n",
    "                con = soup.find_all(\"p\")\n",
    "                \n",
    "                Content = \"\"\n",
    "                #這段會多抓出幾個字\n",
    "#                 for i0 in range(len(con)):\n",
    "#                     tmp = con[i0].get_text()\n",
    "#                     Content = Content + tmp\n",
    "#                 Content=\"\".join(Content.split()).replace(\"\\n\",\" \").replace(\"\\\\\",\"\\\\\\\\\").replace('\"',r'\\\"')\n",
    "                \n",
    "                if Content =='':\n",
    "                    con = soup.find_all('div',{\"itemprop\":\"articleBody\"})\n",
    "                    for i0 in range(len(con)):\n",
    "                        tmp = con[i0].get_text()\n",
    "                        Content = Content + tmp\n",
    "                    Content=\"\".join(Content.split()).replace(\"\\n\",\" \").replace(\"\\\\\",\"\\\\\\\\\").replace('\"',r'\\\"')\n",
    "#                 if len(Content)>=50000:\n",
    "#                     Content=\"\"\n",
    "#                     print(\"太長\")\n",
    "                \n",
    "                \n",
    "                #InsertQuery\n",
    "                InsertQuery = \"\"\"insert into %s(datatime, Newstime, Source, Header, url, Target, Content)\n",
    "                                values(%d,%d,\"%s\",\"%s\",\"%s\",\"%s\",\"%s\")\n",
    "                                \"\"\"%(TableName, int(datatime), int(Newstime), Source, Header, url, Target, Content)\n",
    "                \n",
    "                try:\n",
    "                    Cursor.execute(InsertQuery)\n",
    "                    Database.commit()\n",
    "                except :\n",
    "                    print(url,\"Error\")\n",
    "                \n",
    "Cursor.close()\n",
    "Database.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
